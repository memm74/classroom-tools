#!/usr/bin/env python3
"""
This script is designed to support active reading.  It takes as input
a set of ipython notebook as well as some target cells which define a set
of reading exercises.  The script processes the collection of notebooks
and builds a notebook which summarizes the responses to each question.

Original work by Paul Ruvolo.
Adapted by Oliver Steele
"""

import argparse
import io
import json
import os
import re
import string
import sys
from collections import OrderedDict
from copy import deepcopy
from glob import glob
from json import JSONDecodeError

try:
    import Levenshtein
    import nbconvert
    import nbformat
    import pandas as pd
    from numpy import argmin
except ImportError as e:
    sys.stderr.write('%s. Run pip install -r requirements.txt\n' % e)
    sys.exit(1)

# Constants
#

QUESTION_RE = r'#+ Exercise'
POLL_RE = r'#+ .*(poll|Notes for the Instructors|Reading Journal Feedback)'
ORIGIN_DIRNAME = 'origin'
CLEAR_OUTPUTS = True

# Command-line arguments
#

# Test data for Jupyter / Hydrogen development
if 'ipykernel' in sys.modules:
    sys.argv = [
        'script', 'sd17spring/ReadingJournal', 'day3_reading_journal.ipynb'
    ]

parser = argparse.ArgumentParser(
    description="Download all the forks of a GitHub repository.")
parser.add_argument(
    "repo",
    metavar='REPO_NAME',
    help="GitHub source repo, in format username/repo_name")
parser.add_argument(
    "notebook", metavar='NOTEBOOK', help="Jupyter notebook filename")
args = parser.parse_args(sys.argv[1:])

repo_name = args.repo
nb_name = args.notebook

build_dir = os.path.join('build', repo_name)
processed_notebook_dir = os.path.join(build_dir, "processed_notebooks")
summary_dir = os.path.join(build_dir, 'summaries')

repos_download_dir = os.path.join('./downloads', repo_name.replace('/', '-'))

origin_notebook = os.path.join(repos_download_dir, ORIGIN_DIRNAME, nb_name)
assert os.path.exists(origin_notebook)

student_file = os.path.join('./downloads',
                            repo_name.split('/')[0] + '-students.csv')
student_df = (pd.read_csv(student_file)
              if os.path.exists(student_file) else pd.DataFrame(
                  [], columns=['Student', 'Nickname', 'GitHub']))
student_df = pd.concat(
    [
        student_df, student_df['Full Name'].str.extract(
            '(?P<first>\S+).*?(?P<last>\S+)$', expand=True)
    ],
    axis=1)
student_df['Name'] = student_df['Nickname'].fillna(
    student_df['first']).str.cat(student_df['last'], ' ')
github_id_username_dict = dict(zip(student_df['GitHub'], student_df['Name']))

# Functions
#


def file_owner_from_path(path):
    return os.path.basename(os.path.dirname(path))


def nb_add_metadata(nb, owner=None):
    if owner:
        nb['metadata']['owner'] = owner
    for cell in nb['cells']:
        if cell['cell_type'] == 'markdown' and cell['source']:
            if re.match(QUESTION_RE, cell['source'][0], re.IGNORECASE):
                cell['metadata']['is_question'] = True
            elif re.match(POLL_RE, cell['source'][0], re.IGNORECASE):
                cell['metadata']['is_question'] = True
                cell['metadata']['is_poll'] = True
    return nb


def safe_read_notebook(path, owner=None, clear_outputs=False):
    with open(path) as f:
        try:
            nb = json.load(f)
        except JSONDecodeError as e:
            print(path, e)
            return None
    nb = nb_add_metadata(nb, owner)
    if clear_outputs:
        for cell in nb['cells']:
            if 'outputs' in cell:
                cell['outputs'] = []
    return nb


# The extractor
#


class NotebookExtractor(object):
    """The top-level class for extracting answers from a notebook.

    TODO: add support multiple notebooks
    """

    MATCH_THRESH = 10  # maximum edit distance to consider something a match

    def __init__(self,
                 notebook_template_file,
                 notebooks,
                 include_usernames=False):
        """Initialize with the specified notebook URLs and list of question prompts."""
        self.question_prompts = self.build_question_prompts(
            notebook_template_file)
        self.notebooks = notebooks
        self.usernames = [nb['metadata']['owner'] for nb in notebooks]
        self.include_usernames = include_usernames
        nb_basename = os.path.basename(notebook_template_file)
        self.nb_name_stem = os.path.splitext(nb_basename)[0]

    def build_question_prompts(self, notebook_template_file):
        """Return a list of `QuestionPrompt`.

        Each cell with metadata `is_question` truthy produces an instance of `QuestionPrompt`.
        """
        with open(notebook_template_file, 'r') as fid:
            self.template = nb_add_metadata(json.load(fid))

        prompts = []
        prev_prompt = None
        for idx, cell in enumerate(self.template['cells']):
            is_final_cell = idx + 1 == len(self.template['cells'])
            metadata = cell['metadata']
            if metadata.get('is_question', False):
                cell_source = ''.join(cell['source'])
                if prev_prompt is not None:
                    prompts[-1].stop_md = cell_source
                is_poll = metadata.get(
                    'is_poll',
                    'Reading Journal feedback' in cell_source.split('\n')[0])
                prompts.append(
                    QuestionPrompt(
                        question_heading='',
                        name=metadata.get('problem', None),
                        index=len(prompts),
                        start_md=cell_source,
                        stop_md='next_cell',
                        is_optional=metadata.get('is_optional', None),
                        is_poll=is_poll))
                if metadata.get('allow_multi_cell', False):
                    prev_prompt = prompts[-1]
                    # if it's the last cell, take everything else
                    if is_final_cell:
                        prompts[-1].stop_md = ''
                else:
                    prev_prompt = None
        return prompts

    def extract(self):
        """Filter the notebook at the notebook_URL so that it only contains the questions and answers to the reading."""
        nbs = {nb['metadata']['owner']: nb for nb in self.notebooks}

        for prompt in self.question_prompts:
            prompt.answer_status = {}
            for gh_username, notebook_content in nbs.items():
                if notebook_content is None:
                    continue
                suppress_non_answer = bool(prompt.answers)
                response_cells = \
                    prompt.get_closest_match(notebook_content['cells'],
                                             NotebookExtractor.MATCH_THRESH,
                                             suppress_non_answer)
                if not response_cells:
                    status = 'missed'
                elif not response_cells[-1]['source'] or not NotebookUtils.cell_list_text(
                        response_cells):
                    status = 'blank'
                else:
                    status = 'answered'
                    if not suppress_non_answer:
                        # If it's the first notebook with this answer, extract the questions from it.
                        # This is kind of a bass-ackwards way to do this; it's incremental from the previous
                        # strategy.
                        prompt.cells = [
                            cell for cell in response_cells
                            if cell['metadata'].get('is_question', False)
                        ]
                        response_cells = [
                            cell for cell in response_cells
                            if cell not in prompt.cells
                        ]
                    prompt.answers[gh_username] = response_cells
                prompt.answer_status[gh_username] = status

        sort_responses = not self.include_usernames
        sort_responses = False  # FIXME doesn't work because questions are collected into first response
        if sort_responses:

            def cell_slines_length(response_cells):
                return len('\n'.join(''.join(cell['source'])
                                     for cell in response_cells).strip())

            for prompt in self.question_prompts:
                prompt.answers = OrderedDict(
                    sorted(
                        prompt.answers.items(),
                        key=lambda t: cell_slines_length(t[1])))

    def report_missing_answers(self):
        # Report missing answers
        mandatory_questions = [
            prompt for prompt in self.question_prompts
            if not prompt.is_poll and not prompt.is_optional
        ]
        for prompt in mandatory_questions:
            unanswered = sorted(
                (username, status)
                for username, status in prompt.answer_status.items()
                if status != 'answered')
            for username, status in unanswered:
                print("{status} {prompt_name}: {username}".format(
                    status=status.capitalize(),
                    prompt_name=prompt.name,
                    username=username))

    def write_notebook(self, include_html=True):
        suffix = "_responses_with_names" if self.include_usernames else "_responses"
        nb_name = self.nb_name_stem + suffix
        output_file = os.path.join(processed_notebook_dir, nb_name + '.ipynb')
        html_output = os.path.join(processed_notebook_dir, nb_name + '.html')

        remove_duplicate_answers = not self.include_usernames

        filtered_cells = []
        for prompt in self.question_prompts:
            filtered_cells += prompt.cells
            answers = prompt.answers_without_duplicates if remove_duplicate_answers else prompt.answers
            for gh_username, response_cells in answers.items():
                if self.include_usernames:
                    filtered_cells.append(
                        NotebookUtils.markdown_heading_cell(
                            self.gh_username_to_fullname(gh_username), 4))
                filtered_cells.extend(response_cells)

        answer_book = deepcopy(self.template)
        answer_book['cells'] = filtered_cells
        nb = nbformat.from_dict(answer_book)

        print("Writing", output_file)
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with io.open(output_file, 'wt') as fp:
            nbformat.write(nb, fp, version=4)

        if include_html:
            # TODO why is the following necessary?
            nb = nbformat.reads(nbformat.writes(nb, version=4), as_version=4)
            html_content, _ = nbconvert.export_html(nb)
            print("Writing", html_output)
            os.makedirs(os.path.dirname(html_output), exist_ok=True)
            with io.open(html_output, 'w') as fp:
                fp.write(html_content)

    def write_answer_counts(self):
        output_file = os.path.join(
            summary_dir, '%s_response_counts.csv' % self.nb_name_stem)

        df = pd.DataFrame(
            data=[[u in prompt.answers for u in self.usernames]
                  for prompt in self.question_prompts],
            columns=[
                self.gh_username_to_fullname(name) for name in self.usernames
            ], )
        df.index = [prompt.name for prompt in self.question_prompts]
        df.sort_index(axis=1, inplace=True)
        df.insert(0, 'Total', df.sum(axis=1))
        df = pd.concat([
            df, pd.DataFrame(df.sum(axis=0).astype(int), columns=['Total']).T
        ])

        print("Writing", output_file)
        print('Answer counts:')
        print(df['Total'])
        df.to_csv(output_file)

    def write_poll_results(self):
        def user_response_text(username):
            return NotebookUtils.cell_list_text(
                prompt.answers.get(username, []))

        poll_questions = [
            prompt for prompt in self.question_prompts if prompt.is_poll
        ]
        for prompt in poll_questions:
            slug = prompt.name.strip(' .' + string.digits).replace(
                ' ', '_').lower()
            output_file = os.path.join(summary_dir,
                                       '%s_%s.csv' % (self.nb_name_stem, slug))
            print("Writing %s: poll results for %s" % (output_file,
                                                       prompt.name))

            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            df = pd.DataFrame(
                [user_response_text(user_id) for user_id in self.usernames],
                index=[
                    github_id_username_dict.get(user_id, user_id)
                    for user_id in self.usernames
                ],
                columns=['Response'])
            df.index.name = 'Student'
            df.sort_index(axis=1, inplace=True)
            df = df[df['Response'] != '']
            df.to_csv(output_file)


class QuestionPrompt(object):
    def __init__(self,
                 question_heading,
                 start_md,
                 stop_md,
                 name=None,
                 index=None,
                 is_poll=False,
                 is_optional=None):
        """Initialize a question prompt.

        Initialize a question prompt with the specified starting markdown (the question), and stopping
        markdown (the markdown from the next content cell in the notebook).  To read to the end of the
        notebook, set stop_md to the empty string.  The heading to use in the summary notebook before
        the extracted responses is contined in question_heading.
        To omit the question heading, specify the empty string.
        """
        if is_optional is None and start_md:
            is_optional = bool(
                re.search(r'optional', start_md.split('\n')[0], re.I))
        self.question_heading = question_heading
        self._name = name
        self.start_md = start_md
        self.stop_md = stop_md
        self.is_optional = is_optional
        self.is_poll = is_poll
        self.index = index
        self.answers = OrderedDict()
        self.cells = []

    @property
    def answers_without_duplicates(self):
        answers = dict(self.answers)
        answer_strings = set(
        )  # answers to this question, as strings; used to avoid duplicates
        for username, response_cells in self.answers.items():
            answer_string = '\n'.join(''.join(cell['source'])
                                      for cell in response_cells).strip()
            if answer_string in answer_strings:
                del answers[username]
            else:
                answer_strings.add(answer_string)
        return answers

    @property
    def name(self):
        m = re.match(r'^#+\s*(.+)\n', self.start_md)
        if self._name:
            return self._name
        format_str = {
            (False, False): '',
            (False, True): '{title}',
            (True, False): '{number}',
            (True, True): '{number}. {title}'
        }[isinstance(self.index, int), bool(m)]
        return format_str.format(
            number=(self.index or 0) + 1, title=m and m.group(1))

    def get_closest_match(self,
                          cells,
                          matching_threshold,
                          suppress_non_answer_cells=False):
        """Return a list of cells that most closely match the question prompt.

        If no match is better than the matching_threshold, the empty list will be returned.
        """
        return_value = []
        distances = [
            Levenshtein.distance(self.start_md, ''.join(cell['source']))
            for cell in cells
        ]
        if min(distances) > matching_threshold:
            return return_value

        best_match = argmin(distances)
        if self.stop_md == u"next_cell":
            end_offset = 2
        elif len(self.stop_md) == 0:
            end_offset = len(cells) - best_match
        else:
            distances = [
                Levenshtein.distance(self.stop_md, ''.join(cell['source']))
                for cell in cells[best_match:]
            ]
            if min(distances) > matching_threshold:
                return return_value
            end_offset = argmin(distances)
        if len(self.question_heading) != 0 and not suppress_non_answer_cells:
            return_value.append(
                NotebookUtils.markdown_heading_cell(self.question_heading, 2))
        if not suppress_non_answer_cells:
            return_value.append(cells[best_match])
        return_value.extend(cells[best_match + 1:best_match + end_offset])
        return return_value


class NotebookUtils(object):
    @staticmethod
    def markdown_heading_cell(text, heading_level):
        """Create a Markdown cell with the specified text at the specified heading_level.

        E.g. mark_down_heading_cell('Notebook Title','#')
        """
        return {
            'cell_type': 'markdown',
            'metadata': {},
            'source': '#' * heading_level + ' ' + text
        }

    @staticmethod
    def cell_list_text(cells):
        return ''.join(s for cell in cells for s in cell['source']).strip()


# Read the notebooks; do the work
#

student_notebooks = list(
    filter(None.__ne__, (safe_read_notebook(
        path, owner=file_owner_from_path(path), clear_outputs=CLEAR_OUTPUTS
    ) for path in glob(os.path.join(repos_download_dir, '*', nb_name))
                         if file_owner_from_path(path) != ORIGIN_DIRNAME)))

nbe = NotebookExtractor(origin_notebook, student_notebooks)
nbe.extract()

# nbe.report_missing_answers()
nbe.write_notebook(include_html=False)
nbe.write_poll_results()
# nbe.write_answer_counts()
